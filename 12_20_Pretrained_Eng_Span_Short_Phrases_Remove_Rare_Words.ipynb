{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12/20 Pretrained - Eng_Span_Short Phrases - Remove Rare Words.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG4KM2SHnhta",
        "colab_type": "code",
        "outputId": "29bb6403-670d-41b6-ae38-3c2d26a52cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTA8INoynp0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Path of English-Spanish aligned sentences\n",
        "data_path = \"/content/drive/My Drive/Spanish_Bible_Translation/spa.txt\"\n",
        "\n",
        "# There are over 120000 samples. To conserve memory, we will randomly sample 30,000 out of the first 50,000\n",
        "num_samples = 70000\n",
        "lines_to_consider = 80000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSYMM8bwnvLA",
        "colab_type": "code",
        "outputId": "c4c00661-b20a-47f9-c83f-7d77a6e34d2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Read the file\n",
        "with open(data_path, 'r', encoding='utf-8') as p:\n",
        "  lines = p.read().split('\\n')\n",
        "\n",
        "  print(len(lines))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "122937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb_sPpoXxAo1",
        "colab_type": "text"
      },
      "source": [
        "## Text Preprocessing\n",
        "Now that we've read the lines from the file, we will need to perform all the necessary preprocessing steps. In this case, we will convert the sentences to all lower-case and remove and special characters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bfQI-xenzlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Borrowed from \n",
        "# https://github.com/dipanjanS/practical-machine-learning-with-python/blob/master/bonus%20content/feature%20engineering%20text%20data/Feature%20Engineering%20Text%20Data%20-%20Traditional%20Strategies.ipynb\n",
        "import nltk\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "\n",
        "def normalize_document(doc):\n",
        "    # lower case and remove special characters\\whitespaces\n",
        "    doc = re.sub(\"[^\\w\\s]\", \"\", doc);\n",
        "\n",
        "    doc = doc.lower()\n",
        "    doc = doc.strip()\n",
        "    # tokenize document\n",
        "    tokens = wpt.tokenize(doc)\n",
        "\n",
        "    # re-create document from filtered tokens\n",
        "    doc = ' '.join(tokens)\n",
        "    return doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDz_BVGVx05u",
        "colab_type": "text"
      },
      "source": [
        "Looking through the training data, we see that the sentences start out short and tend to get longer as we proceed through the file. To remedy this, we randomize the selection of sentences that we will train our model on. This will make sure our model is validated on a similar set of sentences to the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCcU3Vg2n7Qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Because the translated sentences seem to get longer as we proceed through the file,\n",
        "# we will randomize our selection of the sentences. \n",
        "import random\n",
        "\n",
        "# Store each of the English and Spanish language statements in two arrays\n",
        "eng_sents = []\n",
        "span_sents = []\n",
        "\n",
        "# Select a random set of indices out of the first 50.000 sentences. \n",
        "random_idx = random.sample(range(0, lines_to_consider-1), num_samples)\n",
        "\n",
        "# Grab the randomized lines\n",
        "lines_randomized = []\n",
        "for idx in random_idx:\n",
        "  lines_randomized.append(lines[idx])\n",
        "\n",
        "# Split the lines into English and Spanish equivalents\n",
        "for line in lines_randomized:\n",
        "  eng, span, _ = line.split('\\t')\n",
        "\n",
        "\n",
        "  eng_sents.append(normalize_document(eng))\n",
        "  # Add start and stop tokens to target language phrases \n",
        "  span_sents.append('START_ ' + normalize_document(span) + ' _END')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV8GJDv0oMtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import gensim\n",
        "\n",
        "from collections import defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy39jlIN5LP_",
        "colab_type": "text"
      },
      "source": [
        "Now we create a set containing all English words in the corpus. It's a good idea to see how long the longest sentence is, and the average length of all the sentences. This will help us establish how long we want our input sequences to be. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9mZQ3yDlw3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We create a set to make sure every word is stored only once\n",
        "eng_words = set()\n",
        "\n",
        "for sent in eng_sents:\n",
        "  for word in sent.split():\n",
        "    eng_words.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY353CV_BCyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list of all sentence lengths\n",
        "eng_sent_lens = [len(sent.split()) for sent in eng_sents]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC4ksSMa6oij",
        "colab_type": "code",
        "outputId": "9e87069a-1142-4fbc-d8b3-d4cad0fabb08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Number of unique English words: \", len(eng_words))\n",
        "print(\"Average English sentence length: \", np.mean(eng_sent_lens))\n",
        "print(\"Longest English sentence length: \", np.max(eng_sent_lens))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique English words:  9002\n",
            "Average English sentence length:  4.922657142857143\n",
            "Longest English sentence length:  10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdxgKMO89-p0",
        "colab_type": "code",
        "outputId": "d5a52577-8dfc-4101-df08-1e36dbb30132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(7, 4))\n",
        "\n",
        "# fixed bin size\n",
        "bins = np.arange(0, max(eng_sent_lens)+1, 1) # fixed bin size\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('# of Words')\n",
        "ax1.set_ylabel('Sentence Count')\n",
        "ax1.set_xlim([min(eng_sent_lens)-1, max(eng_sent_lens)+1])\n",
        "ax1.hist(eng_sent_lens, bins=bins, alpha=0.5, color=color)\n",
        "plt.title(\"Distribution of English Sentence Lengths\")\n",
        "\n",
        "\n",
        "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAEYCAYAAACju6QJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIaKAk8IiKigf4/VntEsvRtMA4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiPGFFV3CYEZ",
        "colab_type": "code",
        "outputId": "217487b2-c7d6-4d3f-f722-9c0763c611db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "unique, counts = np.unique(eng_sent_lens, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 53,\n",
              " 2: 2572,\n",
              " 3: 8645,\n",
              " 4: 15956,\n",
              " 5: 18300,\n",
              " 6: 15101,\n",
              " 7: 7571,\n",
              " 8: 1695,\n",
              " 9: 103,\n",
              " 10: 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5EJp6ZQkNWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eng_word_cnts = dict()\n",
        "\n",
        "for sent in eng_sents:\n",
        "  for wrd in sent.split(\" \"):\n",
        "    if wrd in eng_word_cnts:\n",
        "      eng_word_cnts[wrd] += 1\n",
        "    else:\n",
        "      eng_word_cnts[wrd] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8iBhvc-kqpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eng_word_cnts_array = [eng_word_cnts[wrd] for wrd in eng_word_cnts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gty1-eaxsORt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eng_wrds = [wrd for wrd in eng_word_cnts if eng_word_cnts[wrd] > 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8V1kxYy5W_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eng_wrds.append('_UNK_')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU62Az3nwngQ",
        "colab_type": "code",
        "outputId": "4516ed20-5ab0-4bc7-f231-473a65849a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(eng_wrds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4587"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPkO-h6_lNBX",
        "colab_type": "code",
        "outputId": "e77f460d-08cd-4532-ac90-71d222a9df6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(7, 4))\n",
        "\n",
        "# fixed bin size\n",
        "bins = np.arange(0, max(eng_word_cnts_array)+1, 100) # fixed bin size\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('# of Words')\n",
        "ax1.set_ylabel('Sentence Count')\n",
        "ax1.set_xlim([min(eng_word_cnts_array)-1, max(eng_word_cnts_array)+1])\n",
        "ax1.hist(eng_word_cnts_array, bins=bins, alpha=0.5, color=color)\n",
        "plt.title(\"Distribution of English Sentence Lengths\")\n",
        "\n",
        "\n",
        "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAEYCAYAAACju6QJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deZgdZZn38e/PhDViFoIxJJGARDTw\nKmJkc2NEISAYxlcxjKMRcaIOg/s4IPrCoIwwLigzikaJBFQwok4iohhZXGBYAoYlbGnZkhAIJCFg\nECRwv3/U3VBp+3RXJ31yuk7/Ptd1rq566qmn7jrV59ynnvOcKkUEZmZmVi/Pa3UAZmZm1ndO4GZm\nZjXkBG5mZlZDTuBmZmY15ARuZmZWQ07gZmZmNeQEbi0j6VuSPtdPbb1Y0p8lDcn5KyR9oD/azvZ+\nKWlGf7XXh+1+QdLDkh7YzNs9WdL3c3qD57aHdd4n6Q+bJ0LbWJLukfTmVsdhm84J3Joi3yT+Iukx\nSY9IukrShyQ9+z8XER+KiM9XbKvHN5yIuC8inh8RT/dD7M8mr1L7h0TEnE1tu49xvBj4JDA5Il7U\nzfIDJD2TybX82K8/4+jP57ZM0uvy/2KtpNWSrpT0mn5od0B+kGhF4pR0jqQvbM5t2uYztNUBWFs7\nPCJ+I2k48Ebg68A+wNH9uRFJQyNifX+2OUC8GFgVESt7qHN/RIzfXAH1F0kvAC4CPgzMBbYEXg88\n2cq4zOrEZ+DWdBGxNiLmA+8CZkjaAzY8O5A0WtJFeba+WtLvJT1P0nkUiezneXb5aUkTJYWkYyTd\nB1xWKit/KH2JpGslPSppnqRRua0DJC0rx9h5diRpKvAZ4F25vRtz+bNd8hnXZyXdK2mlpHPzQwql\nOGZIui+7v09s9NxIGp7rP5TtfTbbfzOwANgx4zinr897xvz5PLN9TNKvJY0uLX9vbnOVpM81OkPs\n+tzmGe5d2ebdkt7dpf6XJa3JZYc0CO+lABFxfkQ8HRF/iYhfR8RNpXbeL+m2bOsSSTuVlkX26CzJ\n/5lvqPBy4FvAfvm8PZL1t8q47pP0oIqvb7bJZQdIWibpk3k8V0g6urStbSR9JZ+rtZL+UFp3XxW9\nCI9IulHSAX09TtnOYZIW6bneqleUlt0j6VOSbsrt/0jS1qXln86Y75f0gXxudpU0E3g38Ol8Ln5e\n2uSe3bWnBq/Djdkn2wwiwg8/+v0B3AO8uZvy+4AP5/Q5wBdy+osUb7xb5OP1gLprC5gIBHAuMAzY\nplQ2NOtcASwH9sg6PwG+n8sOAJY1ihc4ubNuafkVwAdy+v1AB7AL8Hzgp8B5XWL7Tsb1Soqzypc3\neJ7OBeYB2+W6dwLHNIqzy7q9Lb8C+BNFstwm50/LZZOBPwOvozj7/TLwVHfPQfm5zefyUWC3XDYW\n2D2n35dt/BMwhOLs+v7O49glthcAq4A5wCHAyC7Lp+Vz/PLc7meBq0rLg+IMfgTFB7yHgKmlOP7Q\npb0zgPnAqHyufw58sfQ8rgdOofjfOxR4vDMm4Bv53I3L/dof2CrnV2X95wFvyfkd+viaeBWwkqJ3\naggwI+tuVVrvWmDHjP824EO5bCrwALA7sC3w/Xxudu36GusSR6P2Gr4O/Rh4D3+yss3tfoo3ja6e\nokgGO0XEUxHx+8h3lB6cHBHrIuIvDZafFxG3RMQ64HPAkeplIFZF7wa+GhF3RcSfgROA6drw7P/f\nozirvBG4kSKRbyBjmQ6cEBGPRcQ9wFeA9/Qhlh3zbKn8GFZa/r2IuDOfo7nAnln+DuDnEfGHiPgr\n8P8o3vireAbYQ9I2EbEiIhaXlt0bEd+J4vvyORTHdEzXBiLiUYoPD50fdh6SNF9SZ90PUSTY26L4\neuQ/KM4adyo1c1pEPBIR9wGXl/ZtA5IEzAQ+HhGrI+KxbG96qdpTwCn5v3cxxYeb3fLs8/3ARyNi\neRS9BVdFxJPAPwIXR8TFEfFMRCwAFlIk9L6YCXw7Iq7J9udQfOjbt1TnzIi4PyJWU3z46NzXIymO\n8eKIeJzig1cVjdrbmNehtYgTuG1u44DV3ZR/ieKM69fZPXt8hbaW9mH5vRRnFKMb1O2LHbO9cttD\n2TBRlUeNP05xpt7V6Iypa1vj+hDL/RExostjXYU4dqT0/OSb/6reNpZtv4siwa6Q9AtJL+tue9km\ndL/vZHJ+XxTf4e+RMX0tF+8EfL3zQwnF/4zY8Lmp8hwD7EBxdnp9qb1fZXmnVbHhOIrO9kYDW1P0\nZHS1E/DO8ocnig8lYxvE0chOwCe7tDOB4vnoVOk40vtrorf2NuZ1aC3iBG6bjYoRxuOAvxkhnGeg\nn4yIXYC3AZ+QdGDn4gZN9nZmMKE0/WKKs4uHgXUUb+idcQ1hwzfz3tq9n+JNt9z2euDBXtbr6uGM\nqWtby/vYzsZYATw7+C2/092+yooRcUlEvIUiUd1OcQa9SSLidoru3j2yaCnwwS4fTLaJiKuqNNdl\n/mHgLxRd/Z1tDY+IRgm/67pPAC/pZtlSil6ecozDIuK0Cu12befULu1sGxHnV1h3g+PIhv/zUL1X\npajc8+vQBhgncGs6SS+QdBhwAcX3qjd3U+ewHHgjYC3wNEVXLRSJcZeN2PQ/SposaVuK7zcvzK7d\nO4GtJb1V0hYU369uVVrvQWBiD4N3zgc+LmlnSc+n6I79UfRxJHzGMhc4VdJ22T38CYrvMZvtQuBw\nSftL2pKi61W9rSRpjKRp2U3/JEVX8zO9rNZdOy/LQWPjc34CcBRwdVb5FnCCpN1z+XBJ76zY/IPA\n+NwvIuIZig8ZZ0h6YbY3TtLBvTWU684GvippR0lDJO0naSuK43S4pIOzfOscENfTrwK2yHqdj6EZ\n24ck7aPCsPzf3K7Cvs4Fjpb08vw/73pdhT69dnp5HdoA4wRuzfRzSY9RnGGcCHyVxj8hmwT8hiIh\n/C/wzYi4PJd9Efhsdi9+qg/bP4/irO4Bim7Qj0AxKh74Z+C7FGe764DyqPQf599Vkm7opt3Z2fbv\ngLspztCO60NcZcfl9u+i6Jn4YbZfVeco9fLj//a2Un5vfRzFh6oVFM/7Snr/GdfzKD5k3E/Rrf1G\nisFqffUYxaCtaySto0jct1D87p2I+BlwOnCBpEdzWaMR7V1dBiwGHpD0cJb9G0XX8NXZ3m+A3Sq2\n9yngZuA6in0+HXheRCylGGz3GYpBdEuBf6Xn99WLKXoDOh8nR8RCioF//w2syTjfVyWwiPglcCbF\nGIAOnvsA1HkczwYm52vnfyo02dPr0AaYzlG+ZjaIZU/CI8CkiLi71fHYxlHxM7pbKEawt+O1EazE\nZ+Bmg5SkwyVtm93hX6Y4y7yntVFZX0n6exW/cx9J0TvwcyfvwcEJ3GzwmkbRFX4/RdfpdP9kqJY+\nSPH1x58ovrPemK80rIbchW5mZlZDPgM3MzOroba8mcno0aNj4sSJrQ7DzMxsk11//fUPR8QOXcvb\nMoFPnDiRhQsXtjoMMzOzTSbp3u7K3YVuZmZWQ07gZmZmNeQEbmZmVkNO4GZmZjXkBG5mZlZDTuBm\nZmY15ARuZmZWQ07gZmZmNeQEbmZmVkNtmcAffPQJzlhwJ2csuLPVoZiZmTVFWyZwMzOzducEbmZm\nVkNO4GZmZjXkBG5mZlZDTuBmZmY15ARuZmZWQ07gZmZmNeQEbmZmVkNO4GZmZjXU1AQu6eOSFku6\nRdL5kraWtLOkayR1SPqRpC2z7lY535HLJ5baOSHL75B0cDNjNjMzq4OmJXBJ44CPAFMiYg9gCDAd\nOB04IyJ2BdYAx+QqxwBrsvyMrIekybne7sBU4JuShjQrbjMzszpodhf6UGAbSUOBbYEVwJuAC3P5\nHOCInJ6W8+TyAyUpyy+IiCcj4m6gA9i7yXGbmZkNaE1L4BGxHPgycB9F4l4LXA88EhHrs9oyYFxO\njwOW5rrrs/725fJu1jEzMxuUmtmFPpLi7HlnYEdgGEUXeLO2N1PSQkkL161d06zNmJmZDQjN7EJ/\nM3B3RDwUEU8BPwVeC4zILnWA8cDynF4OTADI5cOBVeXybtZ5VkTMiogpETFl2PCRzdgfMzOzAaOZ\nCfw+YF9J2+Z32QcCtwKXA+/IOjOAeTk9P+fJ5ZdFRGT59BylvjMwCbi2iXGbmZkNeEN7r7JxIuIa\nSRcCNwDrgT8Cs4BfABdI+kKWnZ2rnA2cJ6kDWE0x8pyIWCxpLkXyXw8cGxFPNytuMzOzOmhaAgeI\niJOAk7oU30U3o8gj4gngnQ3aORU4td8DNDMzqylfic3MzKyGnMDNzMxqyAnczMyshpzAzczMasgJ\n3MzMrIacwM3MzGrICdzMzKyGnMDNzMxqyAnczMyshpzAzczMasgJ3MzMrIacwM3MzGrICdzMzKyG\nnMDNzMxqyAnczMyshpzAzczMaqhpCVzSbpIWlR6PSvqYpFGSFkhakn9HZn1JOlNSh6SbJO1VamtG\n1l8iaUazYjYzM6uLpiXwiLgjIvaMiD2BVwOPAz8DjgcujYhJwKU5D3AIMCkfM4GzACSNAk4C9gH2\nBk7qTPpmZmaD1ebqQj8Q+FNE3AtMA+Zk+RzgiJyeBpwbhauBEZLGAgcDCyJidUSsARYAUzdT3GZm\nZgPS5krg04Hzc3pMRKzI6QeAMTk9DlhaWmdZljUq34CkmZIWSlq4bu2a/ozdzMxswGl6Ape0JfA2\n4Mddl0VEANEf24mIWRExJSKmDBvuHnYzM2tvm+MM/BDghoh4MOcfzK5x8u/KLF8OTCitNz7LGpWb\nmZkNWpsjgR/Fc93nAPOBzpHkM4B5pfL35mj0fYG12dV+CXCQpJE5eO2gLDMzMxu0hjazcUnDgLcA\nHywVnwbMlXQMcC9wZJZfDBwKdFCMWD8aICJWS/o8cF3WOyUiVjczbjMzs4GuqQk8ItYB23cpW0Ux\nKr1r3QCObdDObGB2M2I0MzOrI1+JzczMrIacwM3MzGrICdzMzKyGnMDNzMxqyAnczMyshpzAzczM\nasgJ3MzMrIacwM3MzGrICdzMzKyGnMDNzMxqyAnczMyshpzAzczMasgJ3MzMrIacwM3MzGrICdzM\nzKyGmprAJY2QdKGk2yXdJmk/SaMkLZC0JP+OzLqSdKakDkk3Sdqr1M6MrL9E0oxmxmxmZlYHzT4D\n/zrwq4h4GfBK4DbgeODSiJgEXJrzAIcAk/IxEzgLQNIo4CRgH2Bv4KTOpG9mZjZY9ZrAJe1cpayb\nOsOBNwBnA0TEXyPiEWAaMCerzQGOyOlpwLlRuBoYIWkscDCwICJWR8QaYAEwtdc9MzMza2NVzsB/\n0k3ZhRXW2xl4CPiepD9K+q6kYcCYiFiRdR4AxuT0OGBpaf1lWdaofAOSZkpaKGnhurVrKoRnZmZW\nX0MbLZD0MmB3YLikt5cWvQDYumLbewHHRcQ1kr7Oc93lAERESIq+h/23ImIWMAtgwkv36Jc2zczM\nBqqGCRzYDTgMGAEcXip/DPinCm0vA5ZFxDU5fyFFAn9Q0tiIWJFd5Ctz+XJgQmn98Vm2HDigS/kV\nFbZvZmbWthom8IiYB8yTtF9E/G9fG46IByQtlbRbRNwBHAjcmo8ZwGn5d16uMh/4F0kXUAxYW5tJ\n/hLgP0oD1w4CTuhrPGZmZu2kpzPwTh2SPgNMLNePiPdXWPc44AeStgTuAo6m+N59rqRjgHuBI7Pu\nxcChQAfweNYlIlZL+jxwXdY7JSJWV9i2mZlZ26qSwOcBvwd+Azzdl8YjYhEwpZtFB3ZTN4BjG7Qz\nG5jdl22bmZm1syoJfNuI+LemR2JmZmaVVfkZ2UWSDm16JGZmZlZZlQT+UYok/hdJj0p6TNKjzQ7M\nzMzMGuu1Cz0ittscgZiZmVl1vSZwSW/orjwiftf/4ZiZmVkVVQax/WtpemuKG4pcD7ypKRGZmZlZ\nr6p0oZevwoakCcDXmhaRmZmZ9Wpjbie6DHh5fwdiZmZm1VX5Dvy/gM6bgzwP2BO4oZlBmZmZWc+q\nfAe+sDS9Hjg/Iq5sUjxmZmZWQZXvwOfktcxfmkV3NDckMzMz602VLvQDgDnAPYCACZJm+GdkZmZm\nrVOlC/0rwEF5S1AkvRQ4H3h1MwMzMzOzxqqMQt+iM3kDRMSdwBbNC8nMzMx6U2kQm6TvAt/P+X9k\nw4FtZmZmtplVSeAfprhP90dy/nfAWU2LyMzMzHrVsAtd0g6SJkfEkxHx1Yh4e0S8HVgAvKBK45Lu\nkXSzpEWSFmbZKEkLJC3JvyOzXJLOlNQh6SZJe5XamZH1l0iasWm7bGZmVn89fQf+X8DobspHAV/v\nwzb+LiL2jIgpOX88cGlETAIuzXmAQ4BJ+ZhJnuVLGgWcBOxDcR32kzqTvpmZ2WDVUwLftbufikXE\n74FXbMI2p1H8LI38e0Sp/NwoXA2MkDQWOBhYEBGrI2INRQ/A1E3YvpmZWe31lMB7ug941VHoAfxa\n0vWSZmbZmIhYkdMPAGNyehywtLTusixrVL4BSTMlLZS0cN3aNRXDMzMzq6eeEniHpEO7Fko6BLir\nYvuvi4i9KLrHj+16b/GICJ67zvomiYhZETElIqYMG+4edjMza289jUL/GPALSUdS3P8bYAqwH3BY\nlcYjYnn+XSnpZxTfYT8oaWxErMgu8pVZfTkwobT6+CxbDhzQpfyKKts3MzNrVw3PwCNiCfB/gN8C\nE/PxW+AVeTGXHkkaJmm7zmngIOAWYD7QOZJ8BjAvp+cD783R6PsCa7Or/RLgIEkjc/DaQVlmZmY2\naPX4O/CIeBL43ka2PQb4maTO7fwwIn4l6TpgrqRjgHuBI7P+xcChQAfwOHB0xrBa0ueB67LeKRGx\neiNjMjMzawtVLuSyUSLiLuCV3ZSvAg7spjwoLhjTXVuzgdn9HaOZmVldVbkWupmZmQ0wlRK4pG0k\n7dbsYMzMzKyaXhO4pMOBRcCvcn5PSfObHZiZmZk1VuUM/GSKn389AhARi4CdmxiTmZmZ9aJKAn8q\nItZ2KeuXi6+YmZnZxqkyCn2xpH8AhkiaRHFb0auaG5aZmZn1pMoZ+HHA7sCTwA+BtRRXaTMzM7MW\n6fUMPCIeB07Mh5mZmQ0AVUahL5A0ojQ/UpIvZWpmZtZCVbrQR0fEI50zeU/uFzYvJDMzM+tNlQT+\njKQXd85I2gmPQjczM2upKqPQTwT+IOm3gIDXAzObGpWZmZn1qMogtl9J2gvYN4s+FhEPNzcsMzMz\n60nVu5FtBazO+pMlERG/a15YZmZm1pNeE7ik04F3AYuBZ7I4ACdwMzOzFqlyBn4EsFtEPLkxG5A0\nBFgILI+IwyTtDFwAbA9cD7wnIv4qaSvgXODVwCrgXRFxT7ZxAnAM8DTwkYjwz9jMzGxQqzIK/S5g\ni03YxkeB20rzpwNnRMSuwBqKxEz+XZPlZ2Q9JE0GplNcDW4q8M38UGBmZjZoVUngjwOLJH1b0pmd\njyqNSxoPvBX4bs4LeBNwYVaZQ3GGDzAt58nlB2b9acAFEfFkRNwNdFDcHc3MzGzQqtKFPj8fG+Nr\nwKeB7XJ+e+CRiFif88uAcTk9DlgKEBHrJa3N+uOAq0ttltd5lqSZ5M/bRr5wx40M18zMrB6q/Ixs\njqRtgBdHxB1VG5Z0GLAyIq6XdMAmxFhJRMwCZgFMeOkevtCMmZm1tSrXQj8cWAT8Kuf3lFTljPy1\nwNsk3UMxaO1NwNeBEZI6PziMB5bn9HJgQm5jKDCcYjDbs+XdrGNmZjYoVfkO/GSK75wfAYiIRcAu\nva0UESdExPiImEgxCO2yiHg3cDnwjqw2A5iX0/Nznlx+WURElk+XtFWOYJ8EXFshbjMzs7ZV5Tvw\npyJibTGe7FnPNKpcwb8BF0j6AvBH4OwsPxs4T1IHxUVjpgNExGJJc4FbgfXAsRHx9CZs38zMrPaq\nJPDFkv4BGCJpEvAR4Kq+bCQirgCuyOm76GYUeUQ8AbyzwfqnAqf2ZZtmZmbtrEoX+nEUv8F+Evgh\nsJbit91mZmbWIlXOwN8aESdS3JUMAEnvBH7ctKjMzMysR1XOwE+oWGZmZmabScMzcEmHAIcC47pc\nee0FFIPJzMzMrEV66kK/n+ImJG+juOlIp8eAjzczKDMzM+tZwwQeETcCN0r6YUQ8tRljMjMzs15U\nGcS2t6STgZ2yvoCIiF4v5mJmZmbNUSWBn03RZX49xf24zczMrMWqJPC1EfHLpkdiZmZmlVVJ4JdL\n+hLwU4qLuQAQETc0LSozMzPrUZUEvk/+nVIqC4q7i5mZmVkLVLkf+N9tjkDMzMysuir3Ax8j6WxJ\nv8z5yZKOaX5oZmZm1kiVS6meA1wC7JjzdwIfa1ZAZmZm1rsqCXx0RMwl7wEeEevxz8nMzMxaqkoC\nXydpe4qBa0jal+KWoj2StLWkayXdKGmxpH/P8p0lXSOpQ9KPJG2Z5VvlfEcun1hq64Qsv0PSwRux\nn2ZmZm2lSgL/BDAfeImkK4FzKe4R3psngTdFxCuBPYGpmfxPB86IiF2BNUDn9+nHAGuy/Iysh6TJ\nwHSKe5JPBb4paUjF/TMzM2tLvSbw/L33G4H9gQ8Cu0fETRXWi4j4c85ukY/On59dmOVzgCNyelrO\nk8sPlKQsvyAinoyIu4EOYO8K+2ZmZta2GiZwSa+R9CJ49nvvVwOnAl+RNKpK45KGSFoErAQWAH8C\nHsn2AJYB43J6HLC0tL21wPbl8m7WMTMzG5R6OgP/NvBXAElvAE6j6D5fC8yq0nhEPB0RewLjKc6a\nX7ZJ0fZA0kxJCyUtXLd2TbM2Y2ZmNiD0lMCHRMTqnH4XMCsifhIRnwN27ctGIuIR4HJgP2CEpM4L\nyIwHluf0cmACQC4fDqwql3ezTnkbsyJiSkRMGTZ8ZF/CMzMzq50eE3gp0R4IXFZa1usV3CTtIGlE\nTm8DvAW4jSKRvyOrzQDm5fT8nCeXXxYRkeXTc5T6zsAk4Nretm9mZtbOekrE5wO/lfQw8Bfg9wCS\ndqXCz8iAscCcHDH+PGBuRFwk6VbgAklfAP5IcbtS8u95kjqA1RQjz4mIxZLmArcC64FjI8K/Qzcz\ns0GtYQKPiFMlXUqRiH+dZ8NQJONef0aWI9Vf1U35XXQzijwingDe2SgWigF0ZmZmRi9d4RFxdTdl\ndzYvHDMzM6uiyoVczMzMbIBxAjczM6shJ3AzM7MacgI3MzOrISdwMzOzGnICNzMzqyEncDMzsxpy\nAjczM6shJ3AzM7MacgI3MzOrISdwMzOzGnICNzMzqyEncDMzsxpyAjczM6shJ3AzM7MaaloClzRB\n0uWSbpW0WNJHs3yUpAWSluTfkVkuSWdK6pB0k6S9Sm3NyPpLJM1oVsxmZmZ10cwz8PXAJyNiMrAv\ncKykycDxwKURMQm4NOcBDgEm5WMmcBYUCR84CdgH2Bs4qTPpm5mZDVZNS+ARsSIibsjpx4DbgHHA\nNGBOVpsDHJHT04Bzo3A1MELSWOBgYEFErI6INcACYGqz4jYzM6uDzfIduKSJwKuAa4AxEbEiFz0A\njMnpccDS0mrLsqxReddtzJS0UNLCdWvX9Gv8ZmZmA03TE7ik5wM/AT4WEY+Wl0VEANEf24mIWREx\nJSKmDBvuHnYzM2tvTU3gkragSN4/iIifZvGD2TVO/l2Z5cuBCaXVx2dZo3IzM7NBq5mj0AWcDdwW\nEV8tLZoPdI4knwHMK5W/N0ej7wusza72S4CDJI3MwWsHZZmZmdmgNbSJbb8WeA9ws6RFWfYZ4DRg\nrqRjgHuBI3PZxcChQAfwOHA0QESslvR54Lqsd0pErG5i3GZmZgNe0xJ4RPwBUIPFB3ZTP4BjG7Q1\nG5jdf9GZmZnVm6/EZmZmVkNO4GZmZjXkBG5mZlZDTuBmZmY15ARuZmZWQ07gZmZmNeQEbmZmVkNO\n4GZmZjXkBG5mZlZDTuBmZmY15ARuZmZWQ07gZmZmNeQEbmZmVkNO4GZmZjXkBG5mZlZDTUvgkmZL\nWinpllLZKEkLJC3JvyOzXJLOlNQh6SZJe5XWmZH1l0ia0ax4zczM6qSZZ+DnAFO7lB0PXBoRk4BL\ncx7gEGBSPmYCZ0GR8IGTgH2AvYGTOpO+mZnZYNa0BB4RvwNWdymeBszJ6TnAEaXyc6NwNTBC0ljg\nYGBBRKyOiDXAAv72Q4GZmdmgs7m/Ax8TESty+gFgTE6PA5aW6i3Lskblf0PSTEkLJS1ct3ZN/0Zt\nZmY2wLRsEFtEBBD92N6siJgSEVOGDXcvu5mZtbfNncAfzK5x8u/KLF8OTCjVG59ljcrNzMwGtc2d\nwOcDnSPJZwDzSuXvzdHo+wJrs6v9EuAgSSNz8NpBWWZmZjaoDW1Ww5LOBw4ARktaRjGa/DRgrqRj\ngHuBI7P6xcChQAfwOHA0QESslvR54Lqsd0pEdB0YZ2ZmNug0LYFHxFENFh3YTd0Ajm3Qzmxgdj+G\nZmZmVnu+EpuZmVkNOYGbmZnVkBO4mZlZDTmBm5mZ1ZATuJmZWQ05gZuZmdWQE7iZmVkNOYGbmZnV\nkBO4mZlZDTmBm5mZ1ZATuJmZWQ05gZuZmdWQE7iZmVkNOYGbmZnVUNNuJzpQnLHgzmenP/6Wl7Yw\nEjMzs/7jM3AzM7Maqk0ClzRV0h2SOiQd3+p4zMzMWqkWXeiShgDfAN4CLAOukzQ/Im7tSzvuTjcz\ns3ZRiwQO7A10RMRdAJIuAKYBfUrgZeVk3h0neDMzG8jqksDHAUtL88uAfcoVJM0EZubsk584aLdb\nNmWDn9iUlZtvNPBwq4NoIu9f/bX7Pnr/6q1u+7dTd4V1SeC9iohZwCwASQsjYkqLQ2oa71+9tfv+\nQfvvo/ev3tpl/+oyiG05MKE0Pz7LzMzMBqW6JPDrgEmSdpa0JTAdmN/imMzMzFqmFl3oEbFe0r8A\nlwBDgNkRsbiHVWZtnshaxvtXb+2+f9D+++j9q7e22D9FRKtjMDMzsz6qSxe6mZmZlTiBm5mZ1VDb\nJfC6XnJV0gRJl0u6VdJiSR/N8lGSFkhakn9HZrkknZn7eZOkvUptzcj6SyTNaNU+dSVpiKQ/Sroo\n53eWdE3uw49ygCKStsr5jlw+sdTGCVl+h6SDW7Mn3ZM0QtKFkm6XdJuk/drs+H08/zdvkXS+pK3r\nfAwlzZa0UtItpbJ+O16SXqBit5wAAAdYSURBVC3p5lznTEkaAPv3pfz/vEnSzySNKC3r9rg0ek9t\ndOw3l+72r7Tsk5JC0uicr93xqyQi2uZBMcDtT8AuwJbAjcDkVsdVMfaxwF45vR1wJzAZ+E/g+Cw/\nHjg9pw8FfgkI2Be4JstHAXfl35E5PbLV+5exfQL4IXBRzs8Fpuf0t4AP5/Q/A9/K6enAj3J6ch7T\nrYCd81gPafV+lfZvDvCBnN4SGNEux4/iYkp3A9uUjt376nwMgTcAewG3lMr67XgB12Zd5bqHDID9\nOwgYmtOnl/av2+NCD++pjY59K/cvyydQDHi+Fxhd1+NX6TlodQD9fED3Ay4pzZ8AnNDquDZyX+ZR\nXPv9DmBslo0F7sjpbwNHlerfkcuPAr5dKt+gXgv3ZzxwKfAm4KJ8UTxcejN59tjli2+/nB6a9dT1\neJbrtfoBDKdIcOpS3i7Hr/NqiKPymFwEHFz3YwhMZMME1y/HK5fdXirfoF6r9q/Lsr8HfpDT3R4X\nGryn9vT6bfX+ARcCrwTu4bkEXsvj19uj3brQu7vk6rgWxbLRsrvxVcA1wJiIWJGLHgDG5HSjfR2o\nz8HXgE8Dz+T89sAjEbE+58txPrsPuXxt1h+o+wbFWctDwPdUfE3wXUnDaJPjFxHLgS8D9wErKI7J\n9bTXMYT+O17jcrpr+UDyfoozS+j7/vX0+m0ZSdOA5RFxY5dF7Xj82i6B156k5wM/AT4WEY+Wl0Xx\nUbB2v/uTdBiwMiKub3UsTTSUojvvrIh4FbCOogv2WXU9fgD5XfA0ig8qOwLDgKktDarJ6ny8eiPp\nRGA98INWx9JfJG0LfAb4f62OZXNptwRe60uuStqCInn/ICJ+msUPShqby8cCK7O80b4OxOfgtcDb\nJN0DXEDRjf51YISkzosJleN8dh9y+XBgFQNz3zotA5ZFxDU5fyFFQm+H4wfwZuDuiHgoIp4Cfkpx\nXNvpGEL/Ha/lOd21vOUkvQ84DHh3fkiBvu/fKhof+1Z5CcUHzBvzvWY8cIOkF9FGx28Dre7D7+fv\nQ4ZSDELYmecGXOze6rgqxi7gXOBrXcq/xIaDav4zp9/KhoMyrs3yURTfxY7Mx93AqFbvX2l/DuC5\nQWw/ZsNBMP+c08ey4QCouTm9OxsOtLmLgTWI7ffAbjl9ch67tjh+FHf/WwxsmzHPAY6r+zHkb78D\n77fjxd8Ogjp0AOzfVIrbMO/QpV63x4Ue3lMbHftW7l+XZffw3HfgtTx+ve5/qwNowgE9lGIE95+A\nE1sdTx/ifh1Fd91NwKJ8HErxXdOlwBLgN6V/LgHfyP28GZhSauv9QEc+jm71vnXZzwN4LoHvki+S\njnwz2CrLt875jly+S2n9E3Of72CAjQoF9gQW5jH8n3xDaJvjB/w7cDtwC3BevtnX9hgC51N8n/8U\nRQ/KMf15vIAp+Vz9CfhvugxwbNH+dVB859v5HvOt3o4LDd5TGx37Vu5fl+X38FwCr93xq/LwpVTN\nzMxqqN2+AzczMxsUnMDNzMxqyAnczMyshpzAzczMasgJ3MzMrIacwM3alKQvSvo7SUdIOqGP6+6Q\nd5r6o6TXl8qnSfqf0vwJkjpK84dLmr8JMR+gvFudmfXMCdysfe0DXA28EfhdH9c9ELg5Il4VEb8v\nlV9FcXGLTvsBj0p6Yc7vn3UqkTSkj3GZWXICN2szec/nm4DXAP8LfAA4S9LfXCNa0kRJl+U9ki+V\n9GJJe1LcVnOapEWStumsHxEPUSTsXbNoHMXlf/fP+f2BK7Pto/J+yrdIOr20zT9L+oqkG4H98n7T\nt0u6AXh7qd4bc/uLsidgu/57lszqzwncrM1ExL9SXHXrHIokflNEvCIiTumm+n8BcyLiFRQ3tjgz\nIhZR3BDiRxGxZ0T8pcs6VwL7S9qN4oplV+f8UIrbOF4naUeK+02/ieIKda+RdESuP4zifsyvpLhy\n3XeAw4FXAy8qbedTwLERsSfweqBrHGaDmhO4WXvai+K61S8Dbuuh3n7AD3P6PIpL+vbmKooz7f0p\nzvCvpeiufxXFPZSfoPjgcEUUNz/pvOvVG3L9pynO2sn47o6IJVFcFvL7pe1cCXxV0keAEfHcrSvN\njOJC9WbWJrL7+xyKuyc9TN58RNIiYL9uzqY3xpUUNzIZAnwnIh6TtDXFde6rfP/9REQ83VuliDhN\n0i8orsV9paSDI+L2TYjbrK34DNysjUTEouxyvhOYDFwGHNygKxyKhDs9p99NcUe13txGcU/w1wF/\nzLJFwIfI778pzsrfKGl0DlQ7CvhtN23dDkyU9JKcP6pzgaSXRMTNEXE6cB3F2bqZJSdwszYjaQdg\nTUQ8A7wsIm7tofpxwNE56O09wEd7az+7uq8BVkVxb3AoutJ3Ic/AI2IFxe04L6foyr8+IuZ109YT\nwEzgFzmIbWVp8cdyANxNFHec+mVvsZkNJr4bmZmZWQ35DNzMzKyGnMDNzMxqyAnczMyshpzAzczM\nasgJ3MzMrIacwM3MzGrICdzMzKyG/j90j4cAEhf2gQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNFinvsYBzT6",
        "colab_type": "text"
      },
      "source": [
        "Visually, we see the sentence lengths seem to follow a normal distribution with a slight skew to the left. For our purposes, setting the input sequence length to 6 should contain over 99% of our sentences while saving RAM when creating the input arrays later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDJphZJAFfGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_seq_len = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8Ck-McQ7FQW",
        "colab_type": "text"
      },
      "source": [
        "Same exercise for the output language:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZkJzDkQl04M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We create a set to make sure every word is stored only once\n",
        "span_words = set()\n",
        "\n",
        "for sent in span_sents:\n",
        "  for word in sent.split():\n",
        "    span_words.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRza_aSFD5gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list of all Spanish sentence lengths\n",
        "span_sent_lens = [len(sent.split()) for sent in span_sents]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSBXsxo6rfGG",
        "colab_type": "code",
        "outputId": "fa605e3c-0ab0-4d3e-ef00-a4708b9b1d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Number of unique Spanish words: \", len(span_words))\n",
        "print(\"Average Spanish sentence length: \", np.mean(span_sent_lens))\n",
        "print(\"Longest Spanish sentence length: \", max(span_sent_lens))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique Spanish words:  17264\n",
            "Average Spanish sentence length:  6.720285714285715\n",
            "Longest Spanish sentence length:  17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMdVhAgb78T1",
        "colab_type": "code",
        "outputId": "e67e3017-9d7d-401a-9186-6c5561c70afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "fig, ax1 = plt.subplots(figsize=(7, 4))\n",
        "\n",
        "# fixed bin size\n",
        "bins = np.arange(0, max(span_sent_lens)+1, 1) # fixed bin size\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('# of Words')\n",
        "ax1.set_ylabel('Sentence Count')\n",
        "ax1.set_xlim([min(span_sent_lens)-1, max(span_sent_lens)+1])\n",
        "ax1.hist(span_sent_lens, bins=bins, alpha=0.5, color=color)\n",
        "plt.title(\"Distribution of Spanish Sentence Lengths\")\n",
        "\n",
        "\n",
        "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAEYCAYAAACju6QJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKAk8IiKihpLAIyIiauj/Awx8UrPSWwe0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za6kz6uCEShn",
        "colab_type": "code",
        "outputId": "b5e07023-c058-43a2-dc33-baa708da2e54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "unique, counts = np.unique(span_sent_lens, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 620,\n",
              " 4: 4215,\n",
              " 5: 11267,\n",
              " 6: 16725,\n",
              " 7: 16220,\n",
              " 8: 11546,\n",
              " 9: 6196,\n",
              " 10: 2299,\n",
              " 11: 673,\n",
              " 12: 180,\n",
              " 13: 42,\n",
              " 14: 14,\n",
              " 15: 1,\n",
              " 16: 1,\n",
              " 17: 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVOpOJkCE8jg",
        "colab_type": "text"
      },
      "source": [
        "The distribution of the Spanish sentences appears to have a tail on the right side. It appears we can contain 99% of our sentences by clipping the output sequence length at 11. This should save us quite a bit of RAM later on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXxUNqy_FkM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_seq_len = 11"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANEPhKBU1lrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "span_word_cnts = dict()\n",
        "\n",
        "for sent in span_sents:\n",
        "  for wrd in sent.split(\" \"):\n",
        "    if wrd in span_word_cnts:\n",
        "      span_word_cnts[wrd] += 1\n",
        "    else:\n",
        "      span_word_cnts[wrd] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClqY8eWw1lgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "span_word_cnts_array = [span_word_cnts[wrd] for wrd in span_word_cnts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjOpxEsn1lNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "span_wrds = [wrd for wrd in span_word_cnts if span_word_cnts[wrd] > 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLTOqqcD5wVd",
        "colab_type": "code",
        "outputId": "c87ecfbb-0d5b-4e1a-c09d-f7ff46113008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "span_wrds.append('_UNK_')\n",
        "print(len(span_wrds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdz2X5Sxl6GD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_words = sorted(list(eng_wrds))\n",
        "num_encoder_tokens = len(eng_wrds)\n",
        "del eng_words\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70rKqn74Icmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del eng_wrds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG1IRyDomc63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_words = sorted(list(span_wrds))\n",
        "num_decoder_tokens = len(span_wrds)\n",
        "del span_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uadL1tVLIfpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del span_wrds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLR7dJammt9k",
        "colab_type": "text"
      },
      "source": [
        "# Import FastText Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "422bfcsUFpwV",
        "colab_type": "text"
      },
      "source": [
        "For this exercise, we want to see if using the pretrained embeddings provided by Facebook's Fasttext will give our model an edge. Using pretrained embeddings should provide an advantage because the embeddings bring in much more context knowledge for the individual words based on a much larger sample corpus of millions of texts. Our dataset provides nowhere near enough training material."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g09wwW_foOmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import FastText"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uZEQ4t_oUFt",
        "colab_type": "code",
        "outputId": "ea21584f-9a79-44ad-95fd-d84a1272e631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "ft_eng = KeyedVectors.load(\"/content/drive/My Drive/Spanish_Bible_Translation/fasttext_gensim_en.model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7VCz935JcXX",
        "colab_type": "text"
      },
      "source": [
        "### Handling Out-of-Vocabulary (OOV) Words\n",
        "In any large corpus, you are bound to encounter words that the popular pretrained word embeddings like FastText and Word2Vec do not account for. You need a robust way to handle these. \n",
        "\n",
        "One approach is to create random word embeddings for OOV words. However, this introduces the risk of the OOV word embeddings being complete outliers in the word embedding vector space. A simple remedy for this is to take the average and standard deviation of all the other word embeddings in the corpus, and making sure your random embeddings fall within those distributions. This will make sure your OOV word embeddings are not out of this world."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "844l9PCuoJel",
        "colab_type": "code",
        "outputId": "99d67159-e80e-4eae-b9e8-7b0c4a5fc7e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_oov_words = []\n",
        "\n",
        "for i, wrd in enumerate(input_words):\n",
        "  if wrd not in ft_eng.vocab:\n",
        "    input_oov_words.append(wrd)\n",
        "\n",
        "print(\"Number of English OOV words: \", len(input_oov_words))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of English OOV words:  6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abGM6QVpmV4N",
        "colab_type": "text"
      },
      "source": [
        "We see that the OOV words make up a very small portion of the total vocabulary, which suggests that we are okay to try the method outlined above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhab7AQe4lky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a dictionary that \n",
        "\n",
        "#https://www.kaggle.com/sbongo/do-pretrained-embeddings-give-you-the-extra-edge\n",
        "input_embeddings_index = dict()\n",
        "\n",
        "for i, word in enumerate(input_words):\n",
        "  try:\n",
        "    embedding_vector = ft_eng.get_vector(word)\n",
        "  except KeyError:\n",
        "    embedding_vector = None\n",
        "  #embedding_vector = ft_eng.get_vector(word)\n",
        "  if embedding_vector is not None:\n",
        "    # words not found in embedding index will be all-zeros.\n",
        "    input_embeddings_index[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69m_BudXnNCT",
        "colab_type": "text"
      },
      "source": [
        "To make our OOV word embeddings consistent with the existing word embeddings, we take the mean and standard deviation of the existing word embeddings. The OOV word embeddings now consist of random numbers within the normal range of the existing word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhWOrNGX5saT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.kaggle.com/sbongo/do-pretrained-embeddings-give-you-the-extra-edge\n",
        "#We get the mean and standard deviation of the embedding weights so that we could maintain the \n",
        "        #same statistics for the rest of our own random generated weights. \n",
        "all_embs = np.stack(list(input_embeddings_index.values()))\n",
        "inp_emb_mean,inp_emb_std = all_embs.mean(), all_embs.std()\n",
        "del all_embs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdCz9OVp6m4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.kaggle.com/sbongo/do-pretrained-embeddings-give-you-the-extra-edge\n",
        "input_oov_embeddings = dict()\n",
        "\n",
        "rare_embedding = np.random.normal(inp_emb_mean, inp_emb_std, 300)\n",
        "\n",
        "for wrd in input_oov_words:\n",
        "  input_oov_embeddings[wrd] = np.random.normal(inp_emb_mean, inp_emb_std, 300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRUHdzYL6Tnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del input_embeddings_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5Mj_QivoKCz",
        "colab_type": "text"
      },
      "source": [
        "We now have everything we need to create our input word embedding matrix that consist of the embeddings for every word of every sentence of our training corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lb0G0_VoLUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_embedding_matrix = np.zeros((len(input_words), 300))\n",
        "for i, word in enumerate(input_words):\n",
        "  if word == '_UNK_':\n",
        "    input_embedding_matrix[i] = rare_embedding\n",
        "  else:\n",
        "    try:\n",
        "      embedding_vector = ft_eng.get_vector(word)\n",
        "    except KeyError:\n",
        "      embedding_vector = None\n",
        "    #embedding_vector = ft_eng.get_vector(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all-zeros.\n",
        "      input_embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "      input_embedding_matrix[i] = input_oov_embeddings[word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en8JpFmuoNOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del ft_eng"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNUjRuTTiAvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del input_oov_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoIPrnF-oZAK",
        "colab_type": "text"
      },
      "source": [
        "###  Spanish FastText Word Embeddings\n",
        "We repeat the above procedure for the Spanish language FastText embeddings. At the end we will have the output embedding vectors for every word of every sentence of the training corpus. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyyplrTZDyOX",
        "colab_type": "code",
        "outputId": "722f033a-5e40-42df-95ff-663e5d1d90d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Original fasttext embeddings from https://fasttext.cc/\n",
        "ft_span = KeyedVectors.load(\"/content/drive/My Drive/Spanish_Bible_Translation/fasttext_gensim_span.model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J1zZTyQee2C",
        "colab_type": "code",
        "outputId": "6130b6cd-738b-45bd-f2c7-d1adc1ffadf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output_oov_words = []\n",
        "\n",
        "for i, wrd in enumerate(output_words):\n",
        "  if wrd not in ft_span.vocab:\n",
        "    output_oov_words.append(wrd)\n",
        "\n",
        "print(len(output_oov_words))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EJHbooXB9Fgz",
        "colab": {}
      },
      "source": [
        "#https://www.kaggle.com/sbongo/do-pretrained-embeddings-give-you-the-extra-edge\n",
        "output_embeddings_index = dict()\n",
        "\n",
        "for i, word in enumerate(output_words):\n",
        "  try:\n",
        "    embedding_vector = ft_span.get_vector(word)\n",
        "  except KeyError:\n",
        "    embedding_vector = None\n",
        "  #embedding_vector = ft_span.get_vector(word)\n",
        "  if embedding_vector is not None:\n",
        "    # words not found in embedding index will be all-zeros.\n",
        "    output_embeddings_index[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eTrI5IfG9RFB",
        "colab": {}
      },
      "source": [
        "# https://www.kaggle.com/sbongo/do-pretrained-embeddings-give-you-the-extra-edge\n",
        "#We get the mean and standard deviation of the embedding weights so that we could maintain the \n",
        "        #same statistics for the rest of our own random generated weights. \n",
        "all_embs = np.stack(list(output_embeddings_index.values()))\n",
        "out_emb_mean,out_emb_std = all_embs.mean(), all_embs.std()\n",
        "del all_embs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtTEQ98O9Qrm",
        "colab_type": "code",
        "outputId": "638b22a4-2f5c-4842-f0c1-88c42865d48b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#https://www.kaggle.com/sbongo/do-pretrained-embeddings-give-you-the-extra-edge\n",
        "output_oov_embeddings = dict()\n",
        "\n",
        "for wrd in output_oov_words:\n",
        "  if wrd == \"START_\" or wrd == \"_END\":\n",
        "    print(wrd)\n",
        "    output_oov_embeddings[wrd] = np.zeros(300)\n",
        "  else:\n",
        "    output_oov_embeddings[wrd] = np.random.normal(out_emb_mean, out_emb_std, 300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "START_\n",
            "_END\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xo0Dqfi3eNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "span_rare_embedding = np.random.normal(out_emb_mean, out_emb_std, 300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOTXtOYV9QpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del output_embeddings_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rig9SzPehb-",
        "colab_type": "code",
        "outputId": "58e2da6c-42a0-45bc-d704-a80c7c568879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "output_embedding_matrix = np.zeros((len(output_words), 302))\n",
        "for i, word in enumerate(output_words):\n",
        "  if word == \"START_\":\n",
        "    print(i)\n",
        "    output_embedding_matrix[i, 300] = 1\n",
        "  elif word == \"_END\":\n",
        "    print(i)\n",
        "    output_embedding_matrix[i, 301] = 1\n",
        "  elif word == \"_UNK_\":\n",
        "    output_embedding_matrix[i, :300] = span_rare_embedding\n",
        "  else:\n",
        "    try:\n",
        "      embedding_vector = ft_span.get_vector(word)\n",
        "    except KeyError:\n",
        "      embedding_vector = None\n",
        "    if embedding_vector is not None:\n",
        "      if word == 'START_':\n",
        "        print(word)\n",
        "      # words not found in embedding index will be all-zeros.\n",
        "      output_embedding_matrix[i, :300] = embedding_vector\n",
        "    else:\n",
        "      if word == \"START_\":\n",
        "        print(output_oov_embeddings[word])\n",
        "      output_embedding_matrix[i, :300] = output_oov_embeddings[word]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33\n",
            "34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BWGIhXYbFkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del ft_span"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrt1FRHdk5vB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del output_oov_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYjQU6S8p5Fk",
        "colab_type": "text"
      },
      "source": [
        "## Preparing the Data for our Neural Network\n",
        "In order to train our neural network, we need to convert the text data into numerical data that our neural network can learn from. Up to this point, we have put together the tools necessary to convert our data. Now we need to create the actual matrices that our neural network will use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7X8v5ur75Fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dictionary that stores each word as a unique index\n",
        "input_token_index = dict(\n",
        "    [(word, i) for i, word in enumerate(input_words)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzOiTVMIT5Cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dictionary that stores each word as a unique index\n",
        "target_token_index = dict(\n",
        "    [(word, i) for i, word in enumerate(output_words)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iT_mHTyrZpX",
        "colab_type": "text"
      },
      "source": [
        "We prepare three matrices. The first matrix is the encoder input matrix.\n",
        "\n",
        "The second and third matrices will both be for the decoder. The decoder input matrix sentences will start with the START token. The decoder output matrix will be offset by one token, starting with the first actual token of the sentence. This will train our decoder to predict the next word given the thought vector from the encoder, and the START token. It will then use the output as the input to predict the next token. Training the decoder in this way is called Teacher Forcing. Basically, instead of expecting the decoder to learn to output the whole phrase, we train it at each token and penalize the loss function if the next token is incorrect. Teacher forcing should improve the performance of our model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9WQvNb8yPm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_data = np.zeros((num_samples, input_seq_len), dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWCqbgpgyPjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_input_data = np.zeros((num_samples, output_seq_len), dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSl03cHTVgr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_target_data = np.zeros((num_samples, output_seq_len, len(output_words)), dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cuqMEJzyjxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vectorize the encoder input sentences by storing the word indices in the input matrix\n",
        "for i, input_text in enumerate(eng_sents):\n",
        "    for t, word in enumerate(input_text.split()):\n",
        "      if t < input_seq_len:\n",
        "        if word in input_words:\n",
        "          encoder_input_data[i, t] = input_token_index[word]\n",
        "        else:\n",
        "          # if the word is not in the input_words matrix, store it as '_UNK_' for unknown\n",
        "          encoder_input_data[i, t] = input_token_index['_UNK_']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C2sOewW0TvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vectorize the decoder input and output sentences\n",
        "for i, output_text in enumerate(span_sents):\n",
        "  for t, word in enumerate(output_text.split()):\n",
        "    if word in output_words:\n",
        "      if t < output_seq_len:\n",
        "        decoder_input_data[i, t] = target_token_index[word]\n",
        "\n",
        "      # the decoder output matrix is offset by one token\n",
        "      if t > 0 and t < output_seq_len+1:\n",
        "        decoder_target_data[i, t-1, target_token_index[word]] = 1.\n",
        "    \n",
        "    else:\n",
        "      # if the word is not in the output_words matrix, store it as '_UNK_' for unknown\n",
        "      if t < output_seq_len:\n",
        "        decoder_input_data[i, t] = target_token_index['_UNK_']\n",
        "      if t > 0 and t < output_seq_len+1:\n",
        "        decoder_target_data[i, t-1, target_token_index['_UNK_']] = 1.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No2xwvHyishw",
        "colab_type": "text"
      },
      "source": [
        "## Assembling our Neural Network\n",
        "With our training data vectorized, we are now ready to assemble our encoder-decoder neural network. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAenkb1CAc9E",
        "colab_type": "code",
        "outputId": "ea6ca79f-d73f-4b0f-aba1-d3cff64e80c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras.layers import Input, CuDNNLSTM, Embedding, Dense\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0uUhXh0lJH_",
        "colab_type": "text"
      },
      "source": [
        "### Encoder\n",
        "To take advantage of the pretrained word embeddings that we've imported, we create an Embedding layer and set the weights equal to the input_embedding_matrix. We make sure to set the trainable parameter to False so that our word embeddings stay the same throughout the learning process. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WJadgubAhJr",
        "colab_type": "code",
        "outputId": "bf49e710-3431-41b4-dae1-8c84a3704598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "encoder_inputs = Input(shape=(None,))\n",
        "en_x=  Embedding(len(input_words),\n",
        "                            300,\n",
        "                            weights=[input_embedding_matrix],\n",
        "                            trainable=False)(encoder_inputs)\n",
        "encoder = CuDNNLSTM(50, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(en_x)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0ZhwQ7cqOMy",
        "colab_type": "text"
      },
      "source": [
        "### Decoder \n",
        "Our decoder also consists of an embedding layer to hold our pre-trained FastText word embeddings. This time we set the dimension to 302 to hold the extra START and END token columns. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMVKb9Oq-zpt",
        "colab_type": "code",
        "outputId": "8e1df63b-20d5-4907-c512-86b89578bce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dex=  Embedding(len(output_words),\n",
        "                302,\n",
        "                weights=[output_embedding_matrix],\n",
        "                trainable=False)\n",
        "final_dex= dex(decoder_inputs)\n",
        "\n",
        "\n",
        "decoder_lstm = CuDNNLSTM(50, return_sequences=True, return_state=True)\n",
        "\n",
        "decoder_outputs, _, _ = decoder_lstm(final_dex,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "decoder_dense = Dense(len(output_words), activation='softmax')\n",
        "\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Our neural network model takes both encoder_inputs and decoder_inputs as inputs, with the output being decoder_outputs\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0vd-c-e-zne",
        "colab_type": "code",
        "outputId": "3178cabd-0c9d-4477-9b44-4dab80e77355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    1376100     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 302)    2088330     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)        [(None, 50), (None,  70400       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_2 (CuDNNLSTM)        [(None, None, 50), ( 70800       embedding_2[0][0]                \n",
            "                                                                 cu_dnnlstm_1[0][1]               \n",
            "                                                                 cu_dnnlstm_1[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 6915)   352665      cu_dnnlstm_2[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 3,958,295\n",
            "Trainable params: 493,865\n",
            "Non-trainable params: 3,464,430\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1puyuRZ0F9J9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJGf6Wb5FSgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImUxRhIJrWhN",
        "colab_type": "text"
      },
      "source": [
        "We fit our model and find that the validation loss seems to stabilize after about 115 epochs. We use a traditional 80/20 split of the train validation data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4L4zdn6jVOi",
        "colab_type": "code",
        "outputId": "ecc848ab-2577-4e43-b216-ed5e285661af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x=[encoder_input_data, decoder_input_data], y=decoder_target_data,\n",
        "          batch_size=128,\n",
        "          epochs=70, \n",
        "          validation_split=0.20\n",
        "          )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 56000 samples, validate on 14000 samples\n",
            "Epoch 1/70\n",
            "56000/56000 [==============================] - 33s 593us/step - loss: 1.2441 - acc: 0.3060 - val_loss: 1.4001 - val_acc: 0.2878\n",
            "Epoch 2/70\n",
            "56000/56000 [==============================] - 33s 590us/step - loss: 1.2422 - acc: 0.3064 - val_loss: 1.4021 - val_acc: 0.2873\n",
            "Epoch 3/70\n",
            "56000/56000 [==============================] - 33s 592us/step - loss: 1.2403 - acc: 0.3067 - val_loss: 1.3980 - val_acc: 0.2871\n",
            "Epoch 4/70\n",
            "56000/56000 [==============================] - 33s 588us/step - loss: 1.2388 - acc: 0.3067 - val_loss: 1.3989 - val_acc: 0.2868\n",
            "Epoch 5/70\n",
            "56000/56000 [==============================] - 33s 590us/step - loss: 1.2370 - acc: 0.3073 - val_loss: 1.3988 - val_acc: 0.2873\n",
            "Epoch 6/70\n",
            "56000/56000 [==============================] - 33s 590us/step - loss: 1.2350 - acc: 0.3080 - val_loss: 1.3949 - val_acc: 0.2878\n",
            "Epoch 7/70\n",
            "56000/56000 [==============================] - 33s 592us/step - loss: 1.2329 - acc: 0.3082 - val_loss: 1.3949 - val_acc: 0.2883\n",
            "Epoch 8/70\n",
            "56000/56000 [==============================] - 33s 594us/step - loss: 1.2312 - acc: 0.3083 - val_loss: 1.3954 - val_acc: 0.2871\n",
            "Epoch 9/70\n",
            "56000/56000 [==============================] - 33s 594us/step - loss: 1.2297 - acc: 0.3088 - val_loss: 1.3941 - val_acc: 0.2884\n",
            "Epoch 10/70\n",
            "56000/56000 [==============================] - 33s 598us/step - loss: 1.2282 - acc: 0.3089 - val_loss: 1.3943 - val_acc: 0.2882\n",
            "Epoch 11/70\n",
            "56000/56000 [==============================] - 33s 593us/step - loss: 1.2268 - acc: 0.3094 - val_loss: 1.3892 - val_acc: 0.2891\n",
            "Epoch 12/70\n",
            "56000/56000 [==============================] - 33s 588us/step - loss: 1.2250 - acc: 0.3095 - val_loss: 1.3893 - val_acc: 0.2888\n",
            "Epoch 13/70\n",
            "56000/56000 [==============================] - 33s 588us/step - loss: 1.2236 - acc: 0.3100 - val_loss: 1.3950 - val_acc: 0.2876\n",
            "Epoch 14/70\n",
            "56000/56000 [==============================] - 33s 589us/step - loss: 1.2226 - acc: 0.3103 - val_loss: 1.3891 - val_acc: 0.2895\n",
            "Epoch 15/70\n",
            "56000/56000 [==============================] - 33s 587us/step - loss: 1.2214 - acc: 0.3103 - val_loss: 1.3879 - val_acc: 0.2903\n",
            "Epoch 16/70\n",
            "56000/56000 [==============================] - 33s 586us/step - loss: 1.2195 - acc: 0.3109 - val_loss: 1.3865 - val_acc: 0.2896\n",
            "Epoch 17/70\n",
            "56000/56000 [==============================] - 33s 591us/step - loss: 1.2180 - acc: 0.3111 - val_loss: 1.3863 - val_acc: 0.2893\n",
            "Epoch 18/70\n",
            "56000/56000 [==============================] - 33s 590us/step - loss: 1.2162 - acc: 0.3111 - val_loss: 1.3864 - val_acc: 0.2899\n",
            "Epoch 19/70\n",
            "56000/56000 [==============================] - 33s 588us/step - loss: 1.2152 - acc: 0.3115 - val_loss: 1.3895 - val_acc: 0.2888\n",
            "Epoch 20/70\n",
            "56000/56000 [==============================] - 33s 590us/step - loss: 1.2139 - acc: 0.3117 - val_loss: 1.3880 - val_acc: 0.2895\n",
            "Epoch 21/70\n",
            "56000/56000 [==============================] - 33s 593us/step - loss: 1.2125 - acc: 0.3123 - val_loss: 1.3866 - val_acc: 0.2893\n",
            "Epoch 22/70\n",
            "56000/56000 [==============================] - 33s 587us/step - loss: 1.2110 - acc: 0.3126 - val_loss: 1.3865 - val_acc: 0.2891\n",
            "Epoch 23/70\n",
            "56000/56000 [==============================] - 33s 587us/step - loss: 1.2101 - acc: 0.3125 - val_loss: 1.3834 - val_acc: 0.2905\n",
            "Epoch 24/70\n",
            "56000/56000 [==============================] - 33s 590us/step - loss: 1.2084 - acc: 0.3127 - val_loss: 1.3833 - val_acc: 0.2901\n",
            "Epoch 25/70\n",
            "56000/56000 [==============================] - 33s 589us/step - loss: 1.2075 - acc: 0.3133 - val_loss: 1.3811 - val_acc: 0.2904\n",
            "Epoch 26/70\n",
            "56000/56000 [==============================] - 33s 586us/step - loss: 1.2062 - acc: 0.3134 - val_loss: 1.3820 - val_acc: 0.2905\n",
            "Epoch 27/70\n",
            "56000/56000 [==============================] - 33s 587us/step - loss: 1.2050 - acc: 0.3136 - val_loss: 1.3810 - val_acc: 0.2902\n",
            "Epoch 28/70\n",
            "56000/56000 [==============================] - 33s 589us/step - loss: 1.2038 - acc: 0.3138 - val_loss: 1.3812 - val_acc: 0.2903\n",
            "Epoch 29/70\n",
            "56000/56000 [==============================] - 33s 587us/step - loss: 1.2030 - acc: 0.3142 - val_loss: 1.3816 - val_acc: 0.2902\n",
            "Epoch 30/70\n",
            "56000/56000 [==============================] - 33s 585us/step - loss: 1.2017 - acc: 0.3145 - val_loss: 1.3802 - val_acc: 0.2904\n",
            "Epoch 31/70\n",
            "56000/56000 [==============================] - 33s 588us/step - loss: 1.2011 - acc: 0.3144 - val_loss: 1.3804 - val_acc: 0.2906\n",
            "Epoch 32/70\n",
            "56000/56000 [==============================] - 33s 592us/step - loss: 1.1996 - acc: 0.3149 - val_loss: 1.3787 - val_acc: 0.2907\n",
            "Epoch 33/70\n",
            "56000/56000 [==============================] - 33s 587us/step - loss: 1.1987 - acc: 0.3151 - val_loss: 1.3785 - val_acc: 0.2912\n",
            "Epoch 34/70\n",
            "56000/56000 [==============================] - 33s 589us/step - loss: 1.1975 - acc: 0.3155 - val_loss: 1.3791 - val_acc: 0.2907\n",
            "Epoch 35/70\n",
            "56000/56000 [==============================] - 33s 591us/step - loss: 1.1966 - acc: 0.3155 - val_loss: 1.3786 - val_acc: 0.2915\n",
            "Epoch 36/70\n",
            "56000/56000 [==============================] - 33s 592us/step - loss: 1.1958 - acc: 0.3155 - val_loss: 1.3744 - val_acc: 0.2920\n",
            "Epoch 37/70\n",
            "56000/56000 [==============================] - 33s 590us/step - loss: 1.1948 - acc: 0.3159 - val_loss: 1.3759 - val_acc: 0.2915\n",
            "Epoch 38/70\n",
            "56000/56000 [==============================] - 33s 590us/step - loss: 1.1938 - acc: 0.3163 - val_loss: 1.3764 - val_acc: 0.2914\n",
            "Epoch 39/70\n",
            "56000/56000 [==============================] - 33s 591us/step - loss: 1.1929 - acc: 0.3164 - val_loss: 1.3748 - val_acc: 0.2925\n",
            "Epoch 40/70\n",
            "56000/56000 [==============================] - 33s 587us/step - loss: 1.1921 - acc: 0.3165 - val_loss: 1.3740 - val_acc: 0.2923\n",
            "Epoch 41/70\n",
            "56000/56000 [==============================] - 33s 586us/step - loss: 1.1906 - acc: 0.3170 - val_loss: 1.3740 - val_acc: 0.2916\n",
            "Epoch 42/70\n",
            "56000/56000 [==============================] - 33s 587us/step - loss: 1.1898 - acc: 0.3169 - val_loss: 1.3748 - val_acc: 0.2915\n",
            "Epoch 43/70\n",
            "56000/56000 [==============================] - 33s 588us/step - loss: 1.1888 - acc: 0.3176 - val_loss: 1.3758 - val_acc: 0.2926\n",
            "Epoch 44/70\n",
            "56000/56000 [==============================] - 33s 587us/step - loss: 1.1878 - acc: 0.3175 - val_loss: 1.3735 - val_acc: 0.2921\n",
            "Epoch 45/70\n",
            "56000/56000 [==============================] - 33s 589us/step - loss: 1.1867 - acc: 0.3177 - val_loss: 1.3732 - val_acc: 0.2918\n",
            "Epoch 46/70\n",
            "33024/56000 [================>.............] - ETA: 11s - loss: 1.1814 - acc: 0.3188"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-18b76180fded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m           )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG1a0Q4VAhGY",
        "colab_type": "code",
        "outputId": "45df8e4c-6877-421b-e140-4b62c0aaa6c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "encoder_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None)              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, None, 300)         1376100   \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     [(None, 50), (None, 50),  70400     \n",
            "=================================================================\n",
            "Total params: 1,446,500\n",
            "Trainable params: 70,400\n",
            "Non-trainable params: 1,376,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slOVaimI_0To",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_state_input_h = Input(shape=(50,))\n",
        "decoder_state_input_c = Input(shape=(50,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "final_dex2= dex(decoder_inputs)\n",
        "\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(final_dex2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAwYPcAEDk-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoBqLjVN_0SL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        if sampled_token_index == 51:\n",
        "          print(reverse_target_char_index[sampled_token_index])\n",
        "\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence.split()) > output_seq_len):\n",
        "          print(sampled_char)\n",
        "          print(len(decoded_sentence.split()))\n",
        "          stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A0LP39kTdCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_phrase = \"i see you\"\n",
        "\n",
        "test_phrase_input_vector = np.zeros((1, input_seq_len), dtype='float32')\n",
        "test_phrase__output_vector = np.zeros((1, output_seq_len, len(output_words)), dtype='float32')\n",
        "\n",
        "for t, word in enumerate(test_phrase.split()):\n",
        "  try:\n",
        "    tok_ind = input_token_index[word]\n",
        "  except KeyError:\n",
        "    tok_ind = None\n",
        "  \n",
        "  if tok_ind is not None:\n",
        "    test_phrase_input_vector[0, t] = input_token_index[word]\n",
        "  else:\n",
        "    test_phrase_input_vector[0, t] = input_token_index['_UNK_']\n",
        "\n",
        "#test_phrase_input_vector[0, t+1:, input_token_index[' ']] = 1.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz2oIxYZdPpG",
        "colab_type": "code",
        "outputId": "812ca204-f6a6-4539-ceb7-1571a7f735ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#test_phrase_input_vector\n",
        "print(test_phrase)\n",
        "decoded_sent = decode_sequence(test_phrase_input_vector)\n",
        "\n",
        "print(decoded_sent)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i see you\n",
            "_END\n",
            "3\n",
            " te veo _END\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YReda5R9Tc_B",
        "colab_type": "code",
        "outputId": "ff790092-ebe8-4f8c-a9eb-f3bb4fe678ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#rand_idx = random.sample(test_idx, 100)\n",
        "\n",
        "rand_idx = random.sample(range(0, 70000), 100)\n",
        "\n",
        "for seq_index in rand_idx:\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', eng_sents[seq_index: seq_index + 1])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['come back here immediately']\n",
            "Decoded sentence:  vuelve aqu por favor _END\n",
            "_END\n",
            "9\n",
            "-\n",
            "Input sentence: ['lets do only one thing at a time']\n",
            "Decoded sentence:  solo una vez una vez en la misma _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['i love ice cream']\n",
            "Decoded sentence:  me gusta el _UNK_ _END\n",
            "_END\n",
            "3\n",
            "-\n",
            "Input sentence: ['no way']\n",
            "Decoded sentence:  de nadie _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['they caught foxes with traps']\n",
            "Decoded sentence:  ellos _UNK_ _UNK_ _UNK_ de _UNK_ _END\n",
            "_END\n",
            "4\n",
            "-\n",
            "Input sentence: ['youre so talented']\n",
            "Decoded sentence:  eres tan grande _END\n",
            "_END\n",
            "4\n",
            "-\n",
            "Input sentence: ['there were no jobs']\n",
            "Decoded sentence:  no tenemos muchos _END\n",
            "_END\n",
            "9\n",
            "-\n",
            "Input sentence: ['i didnt mind sitting by myself']\n",
            "Decoded sentence:  no me he estado solo en esa hora _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['whats toms full name']\n",
            "Decoded sentence:  cul es el nombre de tom _END\n",
            "_END\n",
            "4\n",
            "-\n",
            "Input sentence: ['it was from tom']\n",
            "Decoded sentence:  fue de tom _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['tom left mary alone']\n",
            "Decoded sentence:  tom dej a mary _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['what time is it its 320']\n",
            "Decoded sentence:  qu es hora de _UNK_ _END\n",
            "_END\n",
            "9\n",
            "-\n",
            "Input sentence: ['she pleaded with him to not leave']\n",
            "Decoded sentence:  ella no le aconsej que _UNK_ a hacer _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['i was told i couldnt do that']\n",
            "Decoded sentence:  me lo dijo que tena nada _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['my mother is sick in bed']\n",
            "Decoded sentence:  mi madre est en la cama _END\n",
            "_END\n",
            "4\n",
            "-\n",
            "Input sentence: ['tom is mad']\n",
            "Decoded sentence:  tom est loco _END\n",
            "_END\n",
            "4\n",
            "-\n",
            "Input sentence: ['were not poor']\n",
            "Decoded sentence:  no somos estos _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['i cant believe he kissed you']\n",
            "Decoded sentence:  no me puedo hablar contigo _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['tom wears a gold wristwatch']\n",
            "Decoded sentence:  tom lleva _UNK_ un _UNK_ _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['tom cannot drive a car']\n",
            "Decoded sentence:  tom no puede conducir un coche _END\n",
            "_END\n",
            "4\n",
            "-\n",
            "Input sentence: ['try to go slower']\n",
            "Decoded sentence:  _UNK_ a comer _END\n",
            "_END\n",
            "3\n",
            "-\n",
            "Input sentence: ['write me']\n",
            "Decoded sentence:  me _UNK_ _END\n",
            "_END\n",
            "9\n",
            "-\n",
            "Input sentence: ['she acted as if she knew nothing']\n",
            "Decoded sentence:  ella se lo dijo con si tena _UNK_ _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['the bride was radiant']\n",
            "Decoded sentence:  la fue _UNK_ a mary _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['they dont take care of that dog']\n",
            "Decoded sentence:  no le perro y esa es _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['give him my regards']\n",
            "Decoded sentence:  _UNK_ de mi hermano _END\n",
            "_END\n",
            "4\n",
            "-\n",
            "Input sentence: ['tom stayed']\n",
            "Decoded sentence:  tom se _UNK_ _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['economy cars save you money']\n",
            "Decoded sentence:  los _UNK_ _UNK_ _UNK_ dinero _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['have you ever seen one']\n",
            "Decoded sentence:  alguna vez te has visto _END\n",
            "_END\n",
            "4\n",
            "-\n",
            "Input sentence: ['try this sauce']\n",
            "Decoded sentence:  _UNK_ esta _UNK_ _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['im here to help you']\n",
            "Decoded sentence:  estoy aqu para ayudarte _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['he is a scientist and musician']\n",
            "Decoded sentence:  l es un hombre y _UNK_ _END\n",
            "_END\n",
            "3\n",
            "-\n",
            "Input sentence: ['can we go']\n",
            "Decoded sentence:  podemos ir _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['tom made a mistake']\n",
            "Decoded sentence:  tom hizo un error _END\n",
            "_END\n",
            "8\n",
            "-\n",
            "Input sentence: ['ill need to make some more tests']\n",
            "Decoded sentence:  necesito _UNK_ ms hacer ms que hacer _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['the prize wont be given to her']\n",
            "Decoded sentence:  el quin no _UNK_ _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['has tom eaten yet']\n",
            "Decoded sentence:  tom ha estado alguna vez _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['i guess ive gotten lazy']\n",
            "Decoded sentence:  supongo que me he tenido _UNK_ _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['tom struggled to get free']\n",
            "Decoded sentence:  tom se _UNK_ a _UNK_ _END\n",
            "_END\n",
            "3\n",
            "-\n",
            "Input sentence: ['i need them']\n",
            "Decoded sentence:  yo necesito _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['do you have a hobby tom']\n",
            "Decoded sentence:  tienes un poco de tom _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['hes watching me']\n",
            "Decoded sentence:  l me est esperando _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['they bought a new car']\n",
            "Decoded sentence:  ellos se hace un coche nuevo _END\n",
            "_END\n",
            "8\n",
            "-\n",
            "Input sentence: ['his family didnt have much money']\n",
            "Decoded sentence:  su vida no tiene dinero a suficiente _END\n",
            "_END\n",
            "2\n",
            "-\n",
            "Input sentence: ['help me out']\n",
            "Decoded sentence:  aydame _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['you have to go alone']\n",
            "Decoded sentence:  tienes que ir solo _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['the boy knocked the glass over']\n",
            "Decoded sentence:  el nio se _UNK_ el leche _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['tom didnt come back']\n",
            "Decoded sentence:  tom no se ha ido _END\n",
            "_END\n",
            "8\n",
            "-\n",
            "Input sentence: ['tests start next week']\n",
            "Decoded sentence:  ella el _UNK_ el juego el ao _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['i cant see anything from here']\n",
            "Decoded sentence:  no puedo ver nada aqu _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['its on the sofa']\n",
            "Decoded sentence:  est en la cama _END\n",
            "_END\n",
            "8\n",
            "-\n",
            "Input sentence: ['he arrived earlier than usual']\n",
            "Decoded sentence:  l se fue ms tarde de nuevo _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['my telephone doesnt work']\n",
            "Decoded sentence:  mi trabajo no funciona _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['few people think so']\n",
            "Decoded sentence:  algunas personas que son estos _END\n",
            "_END\n",
            "10\n",
            "-\n",
            "Input sentence: ['we waited till 230']\n",
            "Decoded sentence:  nos _UNK_ hasta las y las dos y media _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['tom is younger than mary']\n",
            "Decoded sentence:  tom es ms joven que mary _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['no one ran ahead of him']\n",
            "Decoded sentence:  no se lo _UNK_ _END\n",
            "_END\n",
            "4\n",
            "-\n",
            "Input sentence: ['im a translator']\n",
            "Decoded sentence:  soy un estudiante _END\n",
            "_END\n",
            "8\n",
            "-\n",
            "Input sentence: ['wanna crash at my place']\n",
            "Decoded sentence:  _UNK_ a la puerta en la puerta _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['she set out for thailand']\n",
            "Decoded sentence:  ella _UNK_ por _UNK_ _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['he was determined to go abroad']\n",
            "Decoded sentence:  l fue _UNK_ a ir solo _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['whats the plan for today']\n",
            "Decoded sentence:  qu es el plan para hoy _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['i dont like doctors']\n",
            "Decoded sentence:  no me gustan los de _UNK_ _END\n",
            "_END\n",
            "4\n",
            "-\n",
            "Input sentence: ['youve got mail']\n",
            "Decoded sentence:  tienes el _UNK_ _END\n",
            "_END\n",
            "2\n",
            "-\n",
            "Input sentence: ['try that on']\n",
            "Decoded sentence:  _UNK_ _END\n",
            "_END\n",
            "4\n",
            "-\n",
            "Input sentence: ['im not leaving here']\n",
            "Decoded sentence:  no estoy aqu _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['you broke the washing machine']\n",
            "Decoded sentence:  se _UNK_ el _UNK_ _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['tom drank a glass of milk']\n",
            "Decoded sentence:  tom se un vaso de leche _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['thats just crazy']\n",
            "Decoded sentence:  eso es un poco de _UNK_ _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['let me think a minute']\n",
            "Decoded sentence:  djame estar un poco _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['please come again']\n",
            "Decoded sentence:  por favor ven a nuevo _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['i think ive lost my ticket']\n",
            "Decoded sentence:  creo que he perdido mi coche _END\n",
            "_END\n",
            "4\n",
            "-\n",
            "Input sentence: ['quiet please']\n",
            "Decoded sentence:  por favor _UNK_ _END\n",
            "_END\n",
            "4\n",
            "-\n",
            "Input sentence: ['tom is deceitful']\n",
            "Decoded sentence:  tom es _UNK_ _END\n",
            "_END\n",
            "9\n",
            "-\n",
            "Input sentence: ['i made him paint the house']\n",
            "Decoded sentence:  yo le hice la casa que se _UNK_ _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['thats not a proper thing to say']\n",
            "Decoded sentence:  eso no es solo una _UNK_ _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['the fence needed painting']\n",
            "Decoded sentence:  la tienda se _UNK_ _END\n",
            "_END\n",
            "8\n",
            "-\n",
            "Input sentence: ['its not something anyone can do']\n",
            "Decoded sentence:  no hay nada que lo que _UNK_ _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['tom sleeps all the time']\n",
            "Decoded sentence:  tom todos las horas _END\n",
            "_END\n",
            "8\n",
            "-\n",
            "Input sentence: ['im trying to help a friend']\n",
            "Decoded sentence:  estoy buscando a ayudar a un quiero _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['i am tired of my work']\n",
            "Decoded sentence:  estoy cansado mi trabajo _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['tom worked for mary']\n",
            "Decoded sentence:  tom _UNK_ a mary _END\n",
            "_END\n",
            "8\n",
            "-\n",
            "Input sentence: ['mary bought a fake gucci handbag']\n",
            "Decoded sentence:  mary compr una _UNK_ _UNK_ de dinero _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['tom rejected the offer']\n",
            "Decoded sentence:  tom _UNK_ por la mano _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['tom was with us']\n",
            "Decoded sentence:  tom estaba con nosotros _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['would you like to be famous']\n",
            "Decoded sentence:  me gustara ser _UNK_ _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['i wasnt prepared for that']\n",
            "Decoded sentence:  no me _UNK_ eso _END\n",
            "_END\n",
            "8\n",
            "-\n",
            "Input sentence: ['in life there are ups and downs']\n",
            "Decoded sentence:  la vida no est solo y _UNK_ _END\n",
            "_END\n",
            "3\n",
            "-\n",
            "Input sentence: ['be brief']\n",
            "Decoded sentence:  s _UNK_ _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['dont underestimate your opponent']\n",
            "Decoded sentence:  no te _UNK_ tu _UNK_ _END\n",
            "_END\n",
            "4\n",
            "-\n",
            "Input sentence: ['someone screamed']\n",
            "Decoded sentence:  alguien se _UNK_ _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['were not your enemies']\n",
            "Decoded sentence:  no son tus amigos _END\n",
            "_END\n",
            "9\n",
            "-\n",
            "Input sentence: ['the pencil case is on the table']\n",
            "Decoded sentence:  el deberas est el mesa en la mesa _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['im not against outlawing guns']\n",
            "Decoded sentence:  no estoy _UNK_ a los nios _END\n",
            "_END\n",
            "4\n",
            "-\n",
            "Input sentence: ['let me explain']\n",
            "Decoded sentence:  djame hacer algo _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['i went through a lot of trouble']\n",
            "Decoded sentence:  he _UNK_ mucho dinero _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['do you know anyone in australia']\n",
            "Decoded sentence:  sabes en alguien de la oficina _END\n",
            "_END\n",
            "6\n",
            "-\n",
            "Input sentence: ['are you going to school tomorrow']\n",
            "Decoded sentence:  vas a ir al colegio _END\n",
            "_END\n",
            "5\n",
            "-\n",
            "Input sentence: ['tom jogs every morning']\n",
            "Decoded sentence:  tom se _UNK_ maana _END\n",
            "_END\n",
            "7\n",
            "-\n",
            "Input sentence: ['the cab arrived late']\n",
            "Decoded sentence:  el tren se _UNK_ de tom _END\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrRpvkei_0K6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39MbzVHO_0IQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWDRhldmAhEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsxCaEakAhA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5WalW1cw2T1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer_vec = ft.get_vector('dogs') - ft.get_vector('dog')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxVtJCvezL_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer_vec2 = ft.get_vector('cat') - ft.get_vector('cats')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEVqrrV4zT47",
        "colab_type": "code",
        "outputId": "1db21ec5-c13a-4ce7-a648-42253de3617d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ft.cosine_similarities(answer_vec, [answer_vec2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.7573222], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWqA4ToSxsOX",
        "colab_type": "code",
        "outputId": "a050cf89-fdea-47c1-e5a4-6e0dca44ee7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "ft.most_similar(positive=[answer_vec], topn=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('OCCs', 0.2844681143760681), ('SPMs', 0.2560500204563141)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRMdmTKKzPle",
        "colab_type": "code",
        "outputId": "5f56f981-d394-41eb-df82-3dc74111e550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "ft.most_similar(positive=[answer_vec2], topn=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Units', 0.2607120871543884), ('busloads', 0.24602153897285461)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    }
  ]
}